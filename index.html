<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Efficient In-Context Learning in Vision-Language Models for Egocentric Videos. (EILEV)">
  <meta name="keywords" content="Multimodal, Vision-Language Models, In-Context learning, Videos">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Efficient In-Context Learning in Vision-Language Models for Egocentric Videos</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Efficient In-Context Learning in Vision-Language Models for Egocentric Videos</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sled.eecs.umich.edu/author/keunwoo-peter-yu/">Keunwoo Peter Yu</a>,</span>
            <span class="author-block">
              <a href="https://cozheyuanzhangde.github.io/">Zheyuan Zhang</a>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/umich.edu/hufy">Fengyuan Hu</a>,
            </span>
            <span class="author-block">
              <a href="https://web.eecs.umich.edu/~chaijy/">Joyce Chai</a>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of Michigan</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/yukw777/EILEV"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/teaser.png"
            class="interpolation-image"
            alt="Teaser image for the paper"/>
      <h2 class="subtitle">
        <span class="eilev">EILEV</span> elicits in-context learning capabilities in VLMs for egocentric videos 
        by allowing the model to handle data interleaved with videos and texts, and training it on data 
        with clusters of similar verbs and nouns, a long tail distribution of infrequent items and both 
        homonyms and synonyms. The resulting model not only generates more accurate action narrations 
        than other VLMs with more parameters and training data, but also generalizes to novel, rare actions 
        via in-context learning.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advancements in text-only large language models (LLMs) have highlighted the benefit 
            of in-context learning for adapting to new tasks with a few demonstrations. However, extending 
            in-context learning to large vision-language models (VLMs) using a huge amount of naturalistic 
            vision-language data has shown limited success, particularly for egocentric videos, due to 
            high data collection costs. We propose a novel training method 
            <span class="eilev">E</span>fficient <span class="eilev">I</span>n-context <span class="eilev">L</span>earning 
            on <span class="eilev">E</span>gocentric <span class="eilev">V</span>ideos (<span class="eilev">EILEV</span>), 
            which elicits in-context learning in VLMs for egocentric videos without requiring massive, 
            naturalistic egocentric video datasets. <span class="eilev">EILEV</span> involves architectural 
            and training data adaptations to allow the model to process contexts interleaved with video 
            clips and narrations, sampling of in-context examples with clusters of similar verbs and nouns, 
            use of data with skewed marginal distributions with a long tail of infrequent verbs and nouns, 
            as well as homonyms and synonyms. Our evaluations show that <span class="eilev">EILEV</span>-trained 
            models outperform larger VLMs trained on a huge amount of naturalistic data in in-context learning. 
            Furthermore, they can generalize to not only out-of-distribution, but also novel, rare egocentric 
            videos and texts via in-context learning, demonstrating potential for applications requiring 
            cost-effective training, and rapid post-deployment adaptability. Our code and demo are available 
            on <a href="https://github.com/yukw777/EILEV">GitHub</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Work</h2>

        <div class="content has-text-justified">
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code></code></pre>
  </div>
</section>


<footer class="footer">
  <div align="center" class="container">
<div class="columns is-centered">
        <div class="content">
            This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>. Thanks <a href="https://keunhong.com">Keunhong</a>!
        </div>
      </div>
    </div>
</footer>

</body>
</html>
